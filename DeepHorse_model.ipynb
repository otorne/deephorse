{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVtw6n7bT110"
   },
   "source": [
    "# <font color='darkblue'>DeepHorse Model</font>\n",
    "\n",
    "<img src=\"sha-tin-racecourse-slider-pic-mobile-02.jpg\">\n",
    "\n",
    "\n",
    "## Notebook summary:  \n",
    "* Data pre-processing including labelling logic\n",
    "* Helper functions\n",
    "* DeepHorse v1\n",
    "    * FC model with custom depth/units\n",
    "    * Metrics\n",
    "    * Hyperparam search\n",
    "* Benchmarks\n",
    "    * Uniform model\n",
    "    * Public odds model\n",
    "* DeepHorse v2\n",
    "    * Proof-of-concept end-to-end version\n",
    "    * Scratch-pad exploring Conv2D version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Olaf\\\\OneDrive\\\\Work\\\\StanfordAI\\\\Project\\\\Data\\\\spp')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.random.seed(888)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(888)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Dropout, Conv2D \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import datetime\n",
    "import pydot\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Note R and X_raw require a different set of pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R: Feature-enginered data. Load data, extract features and place-vectors\n",
    "Actual feature engineering on raw data is done in `DeepHorse_feature_engineering.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.read_csv('R.csv', index_col=0)\n",
    "R_original = R.copy()\n",
    "R_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_features = R_original.copy()\n",
    "R_features.drop(labels=['race_id', 'horse_num'], axis=1, inplace=True) # useless\n",
    "# R_features.drop(labels=['win_odds'], axis=1, inplace=True) # strong indicator, experiment with dropping\n",
    "\n",
    "n_h = 14\n",
    "n_rows = int(R_features.shape[0]/n_h)\n",
    "\n",
    "R_place = R_features.pop('place')\n",
    "R_place = np.array(R_place).astype(float)\n",
    "R_place = R_place.reshape((int(n_rows),n_h))\n",
    "\n",
    "numeric_cols = R_features.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "n_f = len(numeric_cols)\n",
    "R_features = R_features[numeric_cols]\n",
    "R_features = np.array(R_features)\n",
    "R_features = R_features.reshape((int(n_rows), n_h, n_f))\n",
    "\n",
    "print('Features shape =', R_features.shape)\n",
    "print('Labels shape =', R_place.shape)\n",
    "print('Num features =', len(numeric_cols))\n",
    "print('Feature names =', numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_raw: Load data and reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = pd.read_csv('X_raw.csv', index_col=0)\n",
    "Xraw_original = Xraw.copy()\n",
    "Xraw_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw_features = Xraw_original.copy()\n",
    "Xraw_features.drop(labels=['race_id', 'horse_num'], axis=1, inplace=True) # useless\n",
    "# R_features.drop(labels=['win_odds'], axis=1, inplace=True) # strong indicator, experiment with dropping\n",
    "\n",
    "n_h = 14\n",
    "n_X_rows = int(Xraw_features.shape[0]/n_h)\n",
    "\n",
    "Xraw_place = Xraw_features.pop('place')\n",
    "Xraw_place = np.array(Xraw_place).astype(float)\n",
    "Xraw_place = Xraw_place.reshape((int(n_X_rows),n_h))\n",
    "\n",
    "numeric_cols = Xraw_features.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "n_X_f = len(numeric_cols)\n",
    "Xraw_features = Xraw_features[numeric_cols]\n",
    "Xraw_features = np.array(Xraw_features)\n",
    "Xraw_features = Xraw_features.reshape((int(n_X_rows), n_h, n_X_f))\n",
    "\n",
    "print('Features shape =', Xraw_features.shape)\n",
    "print('Labels shape =', Xraw_place.shape)\n",
    "print('Num features =', len(numeric_cols))\n",
    "# print('Feature names =', numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set labels from \"place\"\n",
    "Vector of horse places, such that horse_i is in 1-14, replaced by all zeros except a weight on first/second/third place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels(w1, w2, w3, labels):\n",
    "    y = labels.copy() \n",
    "    y[y == 1] = w1\n",
    "    y[y == 2] = w2\n",
    "    y[y == 3] = w3\n",
    "    y[y >= 4] = 0\n",
    "    return y\n",
    "\n",
    "w1 = .5\n",
    "w2 = 0.25\n",
    "w3 = 0.25\n",
    "\n",
    "R_labels = set_labels(w1, w2, w3, R_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw_labels = set_labels(w1, w2, w3, Xraw_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Traindev/Dev/Test split\n",
    "\n",
    "**General principle:** \n",
    "\n",
    "We are building a model to forecast races that will happen in the future. The distribution is expected to change through time for several reasons:\n",
    "* The population of horses / jockeys / trainers changes over time\n",
    "* The ranking/handicapping methodology of the HKJC may be subject to change\n",
    "* Systematic climatic variation (e.g. unusually hot summer)\n",
    "* Etc\n",
    "\n",
    "Therefore the model is trained on race data **before** some cutoff date T and dev/test on race data **after** T.\n",
    "\n",
    "**Method:**\n",
    "* First split chronologically:\n",
    "  * Dev&Test is the most recent races available, e.g. to use the *2019-2020* season, we set m_dev_test = 800\n",
    "  * Train&Traindev is what comes before chronologically\n",
    "\n",
    "* Next sample randomly:\n",
    "    * **Dev** and **Test** sets are sampled randomly from the Dev&Test section\n",
    "\n",
    "    * **Train** and **Train/Dev** are sampled randomly from the Train&Traindev section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dev_test = 2000 #how many examples in the dev+test sections; 1600=2 most recent seasons\n",
    "train_split = 1. #how to split the train&traindev section into train and traindev\n",
    "dev_split = 0.5 #how to split the dev&test section into dev and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = R_features.copy()\n",
    "y = R_labels.copy()\n",
    "np.random.seed(888)\n",
    "\n",
    "m_train_traindev = n_rows - m_dev_test\n",
    "\n",
    "# Dev/Test sets are at the end chronologically\n",
    "X_train_traindev = X[ : m_train_traindev]\n",
    "y_train_traindev = y[ : m_train_traindev]\n",
    "X_dev_test  = X[m_train_traindev : n_rows]\n",
    "y_dev_test  = y[m_train_traindev : n_rows]\n",
    "\n",
    "# Now can shuffle \n",
    "idx1 = np.random.permutation(m_train_traindev)\n",
    "X_train_traindev, y_train_traindev = X_train_traindev[idx1], y_train_traindev[idx1]\n",
    "\n",
    "idx2 = np.random.permutation(m_dev_test)\n",
    "X_dev_test, y_dev_test = X_dev_test[idx2], y_dev_test[idx2]\n",
    "\n",
    "# Split Train and Train/Dev sets\n",
    "m_train = int(m_train_traindev * train_split)\n",
    "X_train = X_train_traindev[ : m_train]\n",
    "y_train = y_train_traindev[ : m_train]\n",
    "X_traindev = X_train_traindev[m_train : ]\n",
    "y_traindev = y_train_traindev[m_train : ]\n",
    "\n",
    "# Split Dev and Test sets\n",
    "m_dev = int(m_dev_test * dev_split)\n",
    "\n",
    "X_dev = X_dev_test[: m_dev] \n",
    "y_dev = y_dev_test[: m_dev]\n",
    "X_test = X_dev_test[m_dev : ]\n",
    "y_test = y_dev_test[m_dev : ]\n",
    "\n",
    "print('# Train set examples = ', X_train.shape[0])\n",
    "print('# Train-Dev set examples = ', X_traindev.shape[0])\n",
    "print('# Dev set examples = ', X_dev.shape[0])\n",
    "print('# Test set examples = ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_raw\n",
    "For v2. Dropping the traindev set here as it was not useful in v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = Xraw_features.copy()\n",
    "yraw = Xraw_labels.copy()\n",
    "\n",
    "# m_train_traindev as above\n",
    "\n",
    "# Dev/Test sets are at the end chronologically\n",
    "Xraw_train = Xraw[ : m_train_traindev]\n",
    "yraw_train = yraw[ : m_train_traindev]\n",
    "Xraw_dev_test  = Xraw[m_train_traindev : n_rows]\n",
    "yraw_dev_test  = yraw[m_train_traindev : n_rows]\n",
    "\n",
    "# Now can shuffle \n",
    "# idx1 = np.random.permutation(m_train_traindev)\n",
    "# X_train_traindev, y_train_traindev = X_train_traindev[idx1], y_train_traindev[idx1]\n",
    "\n",
    "idx2 = np.random.permutation(m_dev_test)\n",
    "Xraw_dev_test, yraw_dev_test = Xraw_dev_test[idx2], yraw_dev_test[idx2]\n",
    "\n",
    "# Split Train and Train/Dev sets\n",
    "# m_train = int(m_train_traindev * train_split)\n",
    "# X_train = X_train_traindev[ : m_train]\n",
    "# y_train = y_train_traindev[ : m_train]\n",
    "# X_traindev = X_train_traindev[m_train : ]\n",
    "# y_traindev = y_train_traindev[m_train : ]\n",
    "\n",
    "# Split Dev and Test sets\n",
    "m_dev = int(m_dev_test * dev_split)\n",
    "\n",
    "Xraw_dev = Xraw_dev_test[: m_dev] \n",
    "yraw_dev = yraw_dev_test[: m_dev]\n",
    "Xraw_test = Xraw_dev_test[m_dev : ]\n",
    "yraw_test = yraw_dev_test[m_dev : ]\n",
    "\n",
    "print('# Train set examples = ', Xraw_train.shape[0])\n",
    "# print('# Train-Dev set examples = ', Xraw_traindev.shape[0])\n",
    "print('# Dev set examples = ', Xraw_dev.shape[0])\n",
    "print('# Test set examples = ', Xraw_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "Xraw_train.shape\n",
    "type(Xraw_train)\n",
    "Xraw_train.mean()\n",
    "yraw_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model -- shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often do my top-i picks end as winner ?\n",
    "top1 = tf.keras.metrics.TopKCategoricalAccuracy(k=1, name=\"top_1\", dtype=None) # = accuracy\n",
    "top2 = tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_2\", dtype=None)\n",
    "top3 = tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top_3\", dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs \n",
    "# top_dir = os.path.join(\"logs\")\n",
    "# log_dir = top_dir + \"/fit/\" #+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepHorse_v1 -- Feature-engineered model\n",
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normLayer = preprocessing.Normalization(name='normalization')\n",
    "normLayer.adapt(X_train)\n",
    "\n",
    "def make_DH(hidden_units: list, p_dropout: float=0.5, name: str=''):\n",
    "    \"\"\" \n",
    "    Create \n",
    "    Input->Flatten->Dense->BN->...->Dense->Softmax\n",
    "    \n",
    "    Inputs -- hidden_units [u_1, ..., u_n] where u_i is the number of hidden units in FC layer i\n",
    "    \n",
    "    Outputs -- the model\n",
    "    \"\"\"\n",
    "    X_input = Input(shape=X_train[0].shape)\n",
    "    X = normLayer(X_input)\n",
    "    X = Flatten(name='flatten')(X)\n",
    "    for u in hidden_units:\n",
    "        X = Dense(u, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Dropout(p_dropout)(X)\n",
    "\n",
    "    X = Dense(14, activation='softmax', name='fc-softmax', kernel_regularizer='l2', bias_regularizer='l2')(X)\n",
    "    mdl = Model(inputs = X_input, outputs = X, name=name)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [60, 60]\n",
    "DH_model = make_DH(units, 0.5) \n",
    "DH_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\")\n",
    "callbacks = [\n",
    "#   EarlyStopping(monitor='val_loss', patience=3),\n",
    "  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', \n",
    "    save_best_only=True),\n",
    "  TensorBoard(logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_in = X_train\n",
    "y_in = y_train\n",
    "\n",
    "DH_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics = [\"accuracy\", top3])\n",
    "DH_model.fit(x=X_in,\n",
    "             y=y_in, \n",
    "             epochs=100,\n",
    "             callbacks=callbacks,\n",
    "             batch_size=64,\n",
    "             verbose=2,\n",
    "             shuffle=True,\n",
    "             validation_data=(X_dev, y_dev)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH_model.evaluate(x=X_train, y=y_train)\n",
    "DH_model.evaluate(x=X_dev, y=y_dev)\n",
    "DH_model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1 Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = os.path.join(\"C:\\\\Users\\\\Olaf\\\\OneDrive\\\\Work\\\\StanfordAI\\\\Project\\\\Data\\\\tf_models\\\\\")\n",
    "\n",
    "L = [1, 2, 3]\n",
    "n = [20, 40, 60]\n",
    "p = [40, 50, 60] #percent\n",
    "\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for l in L:\n",
    "    for u in n: \n",
    "        for p_dropout in p:\n",
    "            l_params = np.full(shape=l, fill_value=u).tolist()\n",
    "            name = 'DeepHorse_v1_L' + str(l) + '_u' + str(u) + '_p' + str(p_dropout)\n",
    "            dh = make_DH(l_params, p_dropout/100., name)\n",
    "            dh.compile(loss='categorical_crossentropy', optimizer=opt, metrics = [\"accuracy\", top1, top2, top3])\n",
    "            dh.fit(x=X_train, y=y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "            dh.save(top_dir + name)\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "hp_search = pd.DataFrame(columns = ['Name', 'hparams', 'Loss (Train)','Loss (Dev)', 'Accuracy (Train)', 'Accuracy (Dev)'])\n",
    "for l in L:\n",
    "    for u in n: \n",
    "        for p_dropout in p:        \n",
    "            name = 'DeepHorse_v1_L' + str(l) + '_u' + str(u) + '_p' + str(p_dropout)\n",
    "            \n",
    "            df = keras.models.load_model(top_dir + name)\n",
    "            res1 = np.array(df.evaluate(x=X_train, y=y_train, verbose=0))\n",
    "            res2 = np.array(df.evaluate(x=X_dev, y=y_dev, verbose=0))\n",
    "\n",
    "            h_params = str(np.full(shape=l, fill_value=u).tolist())\n",
    "            res = {'Name':name, 'hparams':h_params, \\\n",
    "                   'Loss (Train)':res1[0], 'Loss (Dev)':res2[0], 'Accuracy (Train)':res1[1], 'Accuracy (Dev)':res2[1]}\n",
    "            hp_search = hp_search.append(res, ignore_index=True)\n",
    "            i = i+1 \n",
    "\n",
    "hp_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General debugging space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH_model.evaluate(x=X_test[0:1], y=y_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "\n",
    "X_ = X_train\n",
    "y_ = y_train\n",
    "\n",
    "for i in np.random.randint(low=0, high=1000, size=5):\n",
    "    yhat = DH_model.predict(x=X_[i:i+1])\n",
    "    y=y_[i:i+1]\n",
    "    np.dot(yhat, y.T)\n",
    "    print('y=',y, 'argmax=', np.argmax(y))\n",
    "    print('yhat=',yhat, 'argmax=', np.argmax(yhat))\n",
    "    print('acc=',DH_model.evaluate(x=X_[i:i+1], y=y_[i:i+1]))\n",
    "    print('manual cost=',-np.dot(np.log(yhat), y.T))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "layer_name = 'normalization'\n",
    "intermediate_layer_model = keras.Model(inputs=DH_model.input,\n",
    "                                       outputs=DH_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model(X_train)\n",
    "out1 = intermediate_output.numpy()\n",
    "\n",
    "for i in range(17):\n",
    "    print(out1[:,:,i].var())\n",
    "\n",
    "(R_features[0,:,1]-R_features[0,:,1].mean())/np.sqrt(R_features[0,:,1].var())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random \n",
    "X_noise = np.random.standard_normal(X_train.shape)\n",
    "y_noise = np.random.standard_normal(y_train.shape)\n",
    "\n",
    "DH_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics = [\"accuracy\", top3])\n",
    "DH_model.fit(x=X_noise,\n",
    "             y=y_noise, \n",
    "             epochs=30,\n",
    "             batch_size=32,\n",
    "             verbose=2,\n",
    "             shuffle=True,\n",
    "             validation_data=(X_dev, y_dev)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform model (UM)\n",
    "* Select winning horse at random\n",
    "* At most 14 horses per race, so Lower bound is :\n",
    "`LB = 1/14`\n",
    "* Races have different number of participants so exact expectation has to be calculated by looping through races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UM_expected_accuracy(X : np.ndarray):\n",
    "    \"\"\"\n",
    "    Calculate the expected accuracy of the Uniform Model that selects a horse at random.\n",
    "    Note that as each race has a different number of entrants it has to be explicitly calculated.\n",
    "    \"\"\"\n",
    "    expectation = 0.0\n",
    "    num_races = X.shape[0]\n",
    "    for i in range(num_races):\n",
    "        odds_vec = X[i, :, 0]\n",
    "        num_horses = len(odds_vec[odds_vec > 0.0])\n",
    "        if not (num_horses > 0):\n",
    "            print('race ', i)\n",
    "            print(X[i, :, :])\n",
    "        expectation = expectation + 1. / num_horses\n",
    "    expectation = expectation / num_races\n",
    "    \n",
    "    return expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Uniform Lower Bound = ', 1./14)\n",
    "print('Uniform R = ', UM_expected_accuracy(R_features))\n",
    "print('Uniform Train = ', UM_expected_accuracy(X_train))\n",
    "print('Uniform Dev = ', UM_expected_accuracy(X_dev))\n",
    "print('Uniform Test = ', UM_expected_accuracy(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Odds model (PO)\n",
    "In a pari-mutuel system (as in HKJC) the odds are determined by the amount wagered on each horse, i.e. it is a zero-sum process less a spread taken by the track.\n",
    "\n",
    "Consequently the odds reflect the public's implied probability distribution, and the lowest odd horses are expected, by the public, to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Public_Odds_accuracy(X:np.ndarray, y:np.ndarray):\n",
    "    \"\"\"\n",
    "    Public Odds model selects horse with most favorable odds\n",
    "    \n",
    "    Inputs:\n",
    "    X -- Features assuming odds are the front\n",
    "    y -- Labels in one-hot form\n",
    "    \"\"\"\n",
    "\n",
    "    acc = 0.0\n",
    "    num_races = X.shape[0]\n",
    "    assert(num_races == y.shape[0])\n",
    "    for i in range(num_races):\n",
    "        odds_vec = X[i, :, 0]\n",
    "        public_vec = np.zeros(shape=(14,))\n",
    "        j = np.argmin(odds_vec)\n",
    "       \n",
    "        public_vec[j] = 1.0\n",
    "\n",
    "        acc = acc + np.dot(public_vec, y[i])\n",
    "    acc = acc / num_races\n",
    "    return acc\n",
    "        \n",
    "def Public_Odds_accuracy_topk(X:np.ndarray, y:np.ndarray, k:int=1):\n",
    "    \"\"\"\n",
    "    Public Odds model selects horse with most favorable odds\n",
    "    \n",
    "    Inputs:\n",
    "    X -- Features assuming odds are the front\n",
    "    y -- Labels in one-hot form\n",
    "    k -- Top-k predictions (e.g. count if any top-3 prediction is winner)\n",
    "    \"\"\"\n",
    "\n",
    "    acc = 0.0\n",
    "    num_races = X.shape[0]\n",
    "    assert(num_races == y.shape[0])\n",
    "    for i in range(num_races):\n",
    "        odds_vec = X[i, :, 0]\n",
    "        public_vec = np.zeros(shape=(14,))\n",
    "\n",
    "        args = np.argpartition(odds_vec, 2)\n",
    "        for s in range(k):\n",
    "            public_vec[args[s]] = 1.0\n",
    "\n",
    "        acc = acc + np.dot(public_vec, y[i])\n",
    "    acc = acc / num_races\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Public R = ', Public_Odds_accuracy(R_features, R_labels))\n",
    "print('Public Train = ', Public_Odds_accuracy(X_train, y_train))\n",
    "print('Public Dev = ', Public_Odds_accuracy(X_dev, y_dev))\n",
    "print('Public Test = ', Public_Odds_accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Public R = ', Public_Odds_accuracy_topk(R_features, R_labels, 3))\n",
    "print('Public Train = ', Public_Odds_accuracy_topk(X_train, y_train, 3))\n",
    "print('Public Dev = ', Public_Odds_accuracy_topk(X_dev, y_dev, 3))\n",
    "print('Public Test = ', Public_Odds_accuracy_topk(X_test, y_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolton-Chapman model\n",
    "Historical model using a multi-nomial logit.\n",
    "\n",
    "https://www.researchgate.net/publication/292145708_Searching_for_Positive_Returns_at_the_Track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Public Odds vs Deep Horse v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PO_vs_DH_forecasts(X:np.ndarray, y:np.ndarray):\n",
    "    \"\"\"\n",
    "    Count times when PO and DH forecast the same winner\n",
    "    \n",
    "    Inputs:\n",
    "    X -- Features assuming odds are the front\n",
    "    y -- Labels in one-hot form\n",
    "    \"\"\"\n",
    "    public_acc = 0.0\n",
    "    dh_acc = 0.0\n",
    "    public_dh_match = 0.0\n",
    "    \n",
    "    num_races = X.shape[0]\n",
    "    assert(num_races == y.shape[0])\n",
    "    for i in range(num_races):\n",
    "        odds_vec = X[i, :, 0]\n",
    "        public_predict = np.zeros(shape=(14,))\n",
    "        j = np.argmin(odds_vec)\n",
    "        public_predict[j] = 1.0\n",
    "        public_acc = public_acc + np.dot(public_predict, y[i])\n",
    "        \n",
    "        dh_predict = np.zeros(shape=(14,))\n",
    "        yhat = DH_model.predict(x=X[i:i+1])\n",
    "        j = np.argmax(yhat)\n",
    "        dh_predict[j] = 1.0\n",
    "        dh_acc = dh_acc + np.dot(dh_predict, y[i])\n",
    "\n",
    "        public_dh_match = public_dh_match + np.dot(dh_predict, public_predict)\n",
    "\n",
    "    public_acc = public_acc / num_races\n",
    "    dh_acc = dh_acc / num_races\n",
    "    public_dh_match = public_dh_match / num_races\n",
    "    return public_acc, dh_acc, public_dh_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_acc, dh_acc, public_dh_match = PO_vs_DH_forecasts(X_dev, y_dev)\n",
    "\n",
    "print('Public Odds accuracy = ', public_acc)\n",
    "print('DH accuracy = ', dh_acc)\n",
    "print('Public-DH agreement = ', public_dh_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Odds accuracy =  0.07775\n",
      "DH accuracy =  0.1375\n",
      "Public-DH agreement =  0.067\n"
     ]
    }
   ],
   "source": [
    "public_acc, dh_acc, public_dh_match = PO_vs_DH_forecasts(X_test, y_test)\n",
    "\n",
    "print('Public Odds accuracy = ', public_acc)\n",
    "print('DH accuracy = ', dh_acc)\n",
    "print('Public-DH agreement = ', public_dh_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_acc, dh_acc, public_dh_match = PO_vs_DH_forecasts(X_train, y_train)\n",
    "\n",
    "print('Public Odds accuracy = ', public_acc)\n",
    "print('DH accuracy = ', dh_acc)\n",
    "print('Public-DH agreement = ', public_dh_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepHorse_v2 -- end-to-end model\n",
    "### Fully connected proof-of-concept model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normLayer_v2 = preprocessing.Normalization(name='normalization_v2')\n",
    "normLayer_v2.adapt(Xraw_train)\n",
    "\n",
    "def make_DH_v2(hidden_units: list, p_dropout: float=0.5, name: str=''):\n",
    "    \"\"\" \n",
    "    Create \n",
    "    \n",
    "    Outputs -- the model\n",
    "    \"\"\"\n",
    "    X_input = Input(shape=Xraw_train[0].shape)\n",
    "    \n",
    "    # normalization is done at raw data stage\n",
    "    \n",
    "    X = Flatten(name='flatten')(X_input)\n",
    "    for u in hidden_units:\n",
    "        X = Dense(u, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Dropout(p_dropout)(X)\n",
    "\n",
    "    X = Dense(14, activation='softmax', name='fc-softmax', kernel_regularizer='l2', bias_regularizer='l2')(X)\n",
    "    mdl = Model(inputs = X_input, outputs = X, name=name)\n",
    "    \n",
    "    return mdl   \n",
    "        \n",
    "\n",
    "units = [64, 64, 32]\n",
    "DH_model_v2 = make_DH_v2(units, 0.5) \n",
    "DH_model_v2.summary()\n",
    "\n",
    "\n",
    "X_in = Xraw_train\n",
    "y_in = yraw_train\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "DH_model_v2.compile(loss='categorical_crossentropy', optimizer=opt, metrics = [\"accuracy\"])\n",
    "DH_model_v2.fit(x=X_in,\n",
    "                y=y_in, \n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                verbose=2,\n",
    "                shuffle=False\n",
    "                ,validation_data=(Xraw_dev, yraw_dev)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV2D model \n",
    "Convolutional  model for attempting on End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normLayer_v2 = preprocessing.Normalization(name='normalization_v2')\n",
    "normLayer_v2.adapt(Xraw_train)\n",
    "\n",
    "def make_DH_CONV2D(filters: list, p_dropout: float=0.5, name: str=''):\n",
    "    \"\"\" \n",
    "    Create \n",
    "    \n",
    "    Outputs -- the model\n",
    "    \"\"\"\n",
    "    \n",
    "    new_shape = (Xraw_train.shape[1], Xraw_train.shape[2],1)\n",
    "           \n",
    "    F1, F2 = filters\n",
    "    kernel_size = (2,10)\n",
    "    \n",
    "    s = 3\n",
    "    \n",
    "    X_input = Input(shape=new_shape)\n",
    "    X = X_input\n",
    "    \n",
    "    \n",
    "    X = Conv2D(F1, kernel_size, strides=(s,s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)    \n",
    "\n",
    "    X = Conv2D(F2, kernel_size, strides=(s,s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)    \n",
    "        \n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(14, activation='softmax', name='fc-softmax', kernel_regularizer='l2', bias_regularizer='l2')(X)\n",
    "    mdl = Model(inputs = X_input, outputs = X, name=name)\n",
    "    return mdl\n",
    "\n",
    "filters = [10, 5]\n",
    "DH_model_v2 = make_DH_v2(filters, 0.5) \n",
    "DH_model_v2.summary()\n",
    "\n",
    "X_in = Xraw_train\n",
    "y_in = yraw_train\n",
    "\n",
    "# X_noise = np.random.standard_normal(Xraw_train.shape)\n",
    "# y_noise = np.random.standard_normal(yraw_train.shape)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "DH_model_v2.compile(loss='categorical_crossentropy', optimizer=opt, metrics = [\"accuracy\"])\n",
    "DH_model_v2.fit(x=X_in,\n",
    "                y=y_in, \n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                verbose=2,\n",
    "                shuffle=False,\n",
    "                validation_data=(Xraw_dev, yraw_dev)\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
