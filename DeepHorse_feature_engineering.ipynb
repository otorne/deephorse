{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVtw6n7bT110"
   },
   "source": [
    "# <font color='darkblue'>DeepHorse Feature Engineering</font>\n",
    "\n",
    "<img src=\"raceday-nighttime.jpg\">\n",
    "\n",
    "\n",
    "## Notebook objectives: \n",
    "* Load raw data\n",
    "* Extract hand-engineered features\n",
    "* Create race-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Olaf\\\\OneDrive\\\\Work\\\\StanfordAI\\\\Project\\\\Data\\\\spp')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data and collate\n",
    "\n",
    "Raw data supplied as race, horse and record tables per season. \n",
    "\n",
    "Steps:\n",
    "* Load CSV files\n",
    "* Join the seasons vertically into 3 multi-season tables of race, horse, record\n",
    "* Merge the race, horse, record tables horizontally into one table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_races_horses_records(one_season: str) -> list:\n",
    "    \"\"\"\n",
    "    Given a season identifier, load the corresponding race data CSVs and return as DataFrames\n",
    "    \n",
    "    Inputs:\n",
    "    season -- season identifier as string\n",
    "    \n",
    "    Outputs:\n",
    "    list of 3 dfs containing the season data (races, horses, records)\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    \n",
    "    df_races = pd.read_csv(one_season + '-RACE.csv')\n",
    "    df_horses = pd.read_csv(one_season + '-HORSE.csv')\n",
    "    df_records = pd.read_csv(one_season + '-RECORD.csv')\n",
    "    \n",
    "    res = [df_races, df_horses, df_records]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# # debug\n",
    "# season = '2018-2019\\\\2018-2019'\n",
    "# res = load_races_horses_records(season)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_seasons(all_seasons: list) -> list:\n",
    "    \"\"\"\n",
    "    Join the race/horse/record dfs of different seasons vertically so we have one race table, one horse table, one records \n",
    "    table, each containing all seasons\n",
    "    \n",
    "    Inputs:\n",
    "    all_seasons -- list of seasons\n",
    "    \n",
    "    Outputs:\n",
    "    list of 3 dfs containing (races, horses, records) of all seasons\n",
    "    \"\"\"\n",
    "    \n",
    "    df_races_all, df_horses_all, df_records_all = load_races_horses_records(all_seasons[0])\n",
    "    \n",
    "    for season in all_seasons[1:]:\n",
    "        df_races, df_horses, df_records = load_races_horses_records(season)\n",
    "        \n",
    "        df_races_all = pd.concat([df_races_all, df_races], axis=0, join=\"inner\", ignore_index=True)\n",
    "        df_records_all = pd.concat([df_records_all, df_records], axis=0, join=\"inner\", ignore_index=True)\n",
    "        df_horses_all = pd.concat([df_horses_all, df_horses], axis=0, join=\"inner\", ignore_index=True)\n",
    "        \n",
    "        #remove duplicate horse-entries \n",
    "        df_horses_all.drop_duplicates(subset='horse_id', inplace=True, ignore_index=True)\n",
    "    \n",
    "    res = [df_races_all, df_horses_all, df_records_all]\n",
    "    return res\n",
    "\n",
    "#debug\n",
    "# seasons = ['2015-2016\\\\2015-2016','2018-2019\\\\2018-2019']\n",
    "# res = collate_seasons(seasons)\n",
    "# len(collate_seasons(seasons)[0])\n",
    "# res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_races_horses_records(races: pd.DataFrame,\n",
    "                                 horses :pd.DataFrame, \n",
    "                                 records: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Join the tables horizontally : vertical axis is a list of entrants (in multiple races and seasons) and horizontal axis is\n",
    "    a list of features combining from races/horses/records tables\n",
    "    \n",
    "    Inputs: DataFrames\n",
    "    races -- df\n",
    "    horses -- df\n",
    "    records -- df\n",
    "    \n",
    "    Outputs:\n",
    "    races_table -- merge races/horses/records into a single df\n",
    "    \"\"\"\n",
    "    \n",
    "    races_table = pd.merge(left=records, right=races, how=\"inner\", on='race_id', sort=True)\n",
    "    races_table = pd.merge(left=races_table, right=horses, how=\"inner\", on='horse_id', sort=False)\n",
    "    races_table.sort_values(by='race_id', ascending=False, inplace=True, ignore_index=True)\n",
    "    \n",
    "    return races_table\n",
    "\n",
    "# debug\n",
    "# X = collate_races_horses_records(res[0], res[1], res[2])\n",
    "# X.to_csv('x.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create raw data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_id', 'place', 'horse_num', 'horse_id', 'jockey', 'trainer',\n",
       "       'actual_weight', 'horse_weight', 'draw', 'lbw', 'finish_time',\n",
       "       'win_odds', 'race_num', 'date', 'location', 'class', 'distance',\n",
       "       'max_rating', 'min_rating', 'going', 'race_name', 'course', 'prize',\n",
       "       'origin', 'color', 'sex', 'import_type', 'sire', 'dam', 'dams_sire',\n",
       "       'first_race'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_seasons = [\n",
    "    '2003-2004\\\\2003-2004'\n",
    "    ,'2004-2005\\\\2004-2005'\n",
    "    ,'2005-2006\\\\2005-2006'\n",
    "    ,'2006-2007\\\\2006-2007'\n",
    "    ,'2007-2008\\\\2007-2008'\n",
    "    ,'2008-2009\\\\2008-2009'\n",
    "    ,'2009-2010\\\\2009-2010'\n",
    "    ,'2010-2011\\\\2010-2011'\n",
    "    ,'2011-2012\\\\2011-2012'\n",
    "    ,'2012-2013\\\\2012-2013'\n",
    "    ,'2013-2014\\\\2013-2014'\n",
    "    ,'2014-2015\\\\2014-2015'\n",
    "    ,'2015-2016\\\\2015-2016'\n",
    "    ,'2016-2017\\\\2016-2017'\n",
    "    ,'2017-2018\\\\2017-2018'\n",
    "    ,'2018-2019\\\\2018-2019'\n",
    "    ,'2019-2020\\\\2019-2020'\n",
    "]\n",
    "\n",
    "debug_seasons = [\n",
    "    '2014-2015\\\\2014-2015'\n",
    "    ,'2015-2016\\\\2015-2016'\n",
    "    ,'2016-2017\\\\2016-2017'\n",
    "    ,'2017-2018\\\\2017-2018'\n",
    "    ,'2018-2019\\\\2018-2019'\n",
    "    ,'2019-2020\\\\2019-2020'\n",
    "]\n",
    "\n",
    "races_all, horses_all, records_all = collate_seasons(all_seasons)\n",
    "X = collate_races_horses_records(races_all, horses_all, records_all)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols=[\n",
    "    'race_id' # required for indexing\n",
    "    ,'horse_num' # required for indexing\n",
    "    ,'place' # y=labels\n",
    "    ,'horse_id' \n",
    "    ,'jockey'\n",
    "    ,'trainer'\n",
    "    ,'win_odds'\n",
    "    ,'location'\n",
    "    ,'distance'\n",
    "    ,'going'\n",
    "    ,'course'\n",
    "    #,'first_race' # data is corrupted - first_race>race_date often\n",
    "    ,'draw'\n",
    "    ,'actual_weight'\n",
    "    ,'horse_weight'\n",
    "    ,'finish_time' # careful to normalize as distances are different\n",
    "    ,'date'\n",
    "    #,'sire', 'dam', 'dams_sire', # only used for data integrity checking\n",
    "    #,'lbw' # TODO: convert format of length behind winner\n",
    "]\n",
    "X = X[keep_cols]\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting\n",
    "\n",
    "* Add engineered features to create `R` \n",
    "* Convert categoricals to one-hot to create `X_raw`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill blanks, change types etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "for cols in numeric_cols:\n",
    "    X = X[ pd.to_numeric(X[cols], errors='coerce').notnull() ]\n",
    "\n",
    "X = X[ pd.to_numeric(X['place'], errors='coerce').notnull() ]\n",
    "X['place'] = X['place'].astype('int') \n",
    "\n",
    "X['race_id'] = X['race_id'].astype('int') \n",
    "X['horse_num'] = X['horse_num'].astype('int')\n",
    "X['draw'] = X['draw'].astype('int')\n",
    "\n",
    "max_time = 500. #0 means DNF, just set to a high number\n",
    "X['finish_time'].replace(to_replace=0, value=max_time, inplace=True)\n",
    "\n",
    "X['date'] = pd.to_datetime(X['date'])\n",
    "\n",
    "X.to_csv('X.csv')\n",
    "\n",
    "# debug\n",
    "# tmp = np.array(X[numeric_cols])\n",
    "# tmp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R : augment X with hand-engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_1(x):\n",
    "    return pd.DataFrame({'tmp': x-x.shift(-1)})\n",
    "\n",
    "def rec(x, stride):\n",
    "    return pd.DataFrame({'tmp': x.shift(-stride)})\n",
    "\n",
    "def pc_show(srs):\n",
    "    x = srs.reset_index(drop=True)\n",
    "    n = len(x)\n",
    "    pc = np.zeros(n)\n",
    "    for i in range(0, n-1):\n",
    "        num_past_race = len(x[i+1:])\n",
    "        num_shows = len(x[i+1:]<=3)\n",
    "        pc[i] = num_shows/num_past_race\n",
    "            \n",
    "    return pd.DataFrame({'tmp': pc})\n",
    "\n",
    "def rel_time(x):\n",
    "    return pd.DataFrame({'tmp': x / x[x > 0].min()})\n",
    "\n",
    "def d_date(x):\n",
    "    return pd.DataFrame({'tmp': (x-x.shift(-1)).dt.days}) \n",
    "\n",
    "def d_date2(x):\n",
    "    return pd.DataFrame({'tmp': (x-x.iloc[-1]).dt.days}) \n",
    "\n",
    "R=X.copy()\n",
    "\n",
    "R['horse_dist_rec_1'] = R.groupby(['horse_id', 'distance'])['place'].apply(lambda x: rec(x, 1))\n",
    "R['horse_dist_rec_2'] = R.groupby(['horse_id', 'distance'])['place'].apply(lambda x: rec(x, 2))\n",
    "R['horse_dist_course_rec_1'] = R.groupby(['horse_id', 'distance', 'course'])['place'].apply(lambda x: rec(x, 1))\n",
    "R['horse_dist_course_going_rec_1'] = R.groupby(['horse_id', 'distance', 'course', 'going'])['place'].apply(lambda x: rec(x, 1))\n",
    "\n",
    "R['d_actual_weight'] = R.groupby('horse_id')['actual_weight'].apply(delta_1)\n",
    "R['d_horse_weight'] = R.groupby('horse_id')['horse_weight'].apply(delta_1)\n",
    "R['horse_rec_1'] = R.groupby('horse_id')['place'].apply(lambda x: rec(x, 1))\n",
    "R['horse_rec_2'] = R.groupby('horse_id')['place'].apply(lambda x: rec(x, 2))\n",
    "R['horse_rec_3'] = R.groupby('horse_id')['place'].apply(lambda x: rec(x, 3))\n",
    "\n",
    "R['relative_finish_time'] = R.groupby('race_id')['finish_time'].apply(rel_time)\n",
    "R['horse_relative_finish_time_1'] = R.groupby('horse_id')['relative_finish_time'].apply(lambda x: rec(x, 1))\n",
    "R['horse_relative_finish_time_2'] = R.groupby('horse_id')['relative_finish_time'].apply(lambda x: rec(x, 2))\n",
    "R['horse_relative_finish_time_3'] = R.groupby('horse_id')['relative_finish_time'].apply(lambda x: rec(x, 3))\n",
    "R.drop('relative_finish_time', axis=1, inplace=True)\n",
    "\n",
    "R['d_horse_date'] = R.groupby('horse_id')['date'].apply(lambda x: d_date(x))\n",
    "R['horse_seniority'] = R.groupby('horse_id')['date'].apply(lambda x: d_date2(x))\n",
    "R.drop('date', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "R['jockey_rec_1'] = R.groupby('jockey')['place'].apply(lambda x: rec(x, 1))\n",
    "R['jockey_rec_2'] = R.groupby('jockey')['place'].apply(lambda x: rec(x, 2))\n",
    "R['jockey_rec_3'] = R.groupby('jockey')['place'].apply(lambda x: rec(x, 3))\n",
    "\n",
    "\n",
    "R['trainer_rec_1'] = R.groupby('trainer')['place'].apply(lambda x: rec(x, 1))\n",
    "R['trainer_rec_2'] = R.groupby('trainer')['place'].apply(lambda x: rec(x, 2))\n",
    "R['trainer_rec_3'] = R.groupby('trainer')['place'].apply(lambda x: rec(x, 3))\n",
    "R['trainer_dist_rec_1'] = R.groupby(['trainer', 'distance'])['place'].apply(lambda x: rec(x, 1))\n",
    "R['trainer_dist_rec_2'] = R.groupby(['trainer', 'distance'])['place'].apply(lambda x: rec(x, 2))\n",
    "R['trainer_dist_rec_3'] = R.groupby(['trainer', 'distance'])['place'].apply(lambda x: rec(x, 3))\n",
    "R['trainer_dist_course_rec_1'] = R.groupby(['trainer', 'distance', 'course'])['place'].apply(lambda x: rec(x, 1))\n",
    "R['trainer_dist_course_rec_2'] = R.groupby(['trainer', 'distance', 'course'])['place'].apply(lambda x: rec(x, 2))\n",
    "R['trainer_dist_course_rec_3'] = R.groupby(['trainer', 'distance', 'course'])['place'].apply(lambda x: rec(x, 3))\n",
    "R['trainer_dist_course_going_rec_1'] = R.groupby(['trainer', 'distance', 'course', 'going'])['place'].apply(lambda x: rec(x, 1))\n",
    "R['trainer_dist_course_going_rec_2'] = R.groupby(['trainer', 'distance', 'course', 'going'])['place'].apply(lambda x: rec(x, 2))\n",
    "R['trainer_dist_course_going_rec_3'] = R.groupby(['trainer', 'distance', 'course', 'going'])['place'].apply(lambda x: rec(x, 3))\n",
    "\n",
    "R.drop('finish_time', axis=1, inplace=True) # equivalent to the label, super important to drop this\n",
    " \n",
    "# Fill-out newly inserted columns with -1\n",
    "old_cols = keep_cols\n",
    "all_cols = R.columns.tolist()\n",
    "new_cols = [item for item in all_cols if item not in old_cols]\n",
    "for col in new_cols:\n",
    "    R[col] = R[col].fillna(-1).astype('float')\n",
    "\n",
    "# Remove un-used columns\n",
    "unused_cols = ['horse_id', 'jockey', 'trainer', 'location', 'distance', 'going', 'course']\n",
    "R.drop(unused_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_raw: replace X categoricals by one-hots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_id', 'horse_num', 'place', 'horse_id', 'jockey', 'trainer',\n",
       "       'win_odds', 'location', 'distance', 'going', 'course', 'draw',\n",
       "       'actual_weight', 'horse_weight', 'finish_time', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw columns= 587\n",
      "X_raw non-numeric= []\n"
     ]
    }
   ],
   "source": [
    "X_raw = X.copy()\n",
    "\n",
    "dropcols = True\n",
    "if dropcols:\n",
    "    X_raw.drop('horse_id', axis=1, inplace=True)\n",
    "else:\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['horse_id'])\n",
    "\n",
    "dropcols = False\n",
    "if dropcols:\n",
    "    X_raw.drop('trainer', axis=1, inplace=True)\n",
    "    X_raw.drop('jockey', axis=1, inplace=True)\n",
    "else:\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['trainer'])\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['jockey'])\n",
    "\n",
    "dropcols = False\n",
    "if dropcols:\n",
    "    X_raw.drop('location', axis=1, inplace=True)\n",
    "    X_raw.drop('distance', axis=1, inplace=True)\n",
    "    X_raw.drop('course', axis=1, inplace=True)\n",
    "    X_raw.drop('going', axis=1, inplace=True)\n",
    "else:\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['location'])\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['distance'])\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['course'])\n",
    "    X_raw = pd.get_dummies(X_raw, columns=['going'])\n",
    "\n",
    "\n",
    "X_raw.drop('finish_time', axis=1, inplace=True) # equivalent to the label, super important to drop this\n",
    "X_raw.drop('date', axis=1, inplace=True) # equivalent to the label, super important to drop this\n",
    "\n",
    "# don't modify these:\n",
    "# race_id horse_num place \n",
    "\n",
    "# normalize by max:\n",
    "normalize_cols =['win_odds', 'draw', 'actual_weight', 'horse_weight']\n",
    "for col in normalize_cols:\n",
    "    tmp = np.array(X_raw[col])\n",
    "    tmp = tmp / np.max(tmp)\n",
    "    X_raw[col] = tmp\n",
    "\n",
    "X_raw.drop(normalize_cols, axis=1, inplace=True)    \n",
    "    \n",
    "print('X_raw columns=', len(X_raw.columns))\n",
    "print('X_raw non-numeric=', X_raw.select_dtypes(exclude=np.number).columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format into Race input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad races to have length 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_races(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Races have at most 14 horses but sometimes less, therefore pad all races to have 14 rows\n",
    "    Input -- X races df\n",
    "    Output -- X padded    \n",
    "    \"\"\"\n",
    "\n",
    "    X.set_index('race_id', inplace=True)\n",
    "    idx = pd.MultiIndex.from_product([X.index.unique(), range(1,15)], names=['race_id', 'horse_num']) #X['horse_num'].unique()\n",
    "    X.set_index('horse_num', append=True, inplace=True)\n",
    "    X = X.reindex(idx, fill_value=0)\n",
    "    X = X.sort_index(level=[0, 1])\n",
    "    X = X.reset_index()\n",
    "    \n",
    "    return X\n",
    "\n",
    "X_raw = pad_races(X_raw)\n",
    "R = pad_races(R)\n",
    "\n",
    "X_raw.to_csv('X_raw.csv')\n",
    "R.to_csv('R.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic quality control\n",
    "Useful for seeking out blanks/NaNs etc in new sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw var = 547935945048253.75\n",
      "X_raw non-numeric= []\n",
      "X_raw rows= 179480\n",
      "X_raw cols= 7386\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X_raw.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "tmp = np.array(X_raw[numeric_cols])\n",
    "print('X_raw var =', tmp.var())\n",
    "print('X_raw non-numeric=', X_raw.select_dtypes(exclude=np.number).columns.tolist())\n",
    "\n",
    "print('X_raw rows=', len(X_raw))\n",
    "print('X_raw cols=', len(numeric_cols))\n",
    "\n",
    "# for col in numeric_cols:\n",
    "#     tmp = np.array(X_raw[col])\n",
    "#     mx=np.max(tmp)\n",
    "#     print(col, 'max=', mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R mean = 55885050.366676815\n",
      "R non-numeric= []\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = R.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "tmp = np.array(R[numeric_cols])\n",
    "print('R mean =', tmp.mean())\n",
    "print('R non-numeric=', R.select_dtypes(exclude=np.number).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
